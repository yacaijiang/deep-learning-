# 感知器
输入，根据输入和权重，和阈值比较大小，确定输出</br>
感知器的偏置b=-threshold</br>
偏置表示让感知器输出1有多容易的估算。
# 多层感知器（MLP）
# 前馈神经网络
# 递归神经网络
# 梯度下降算法（重点）

# 改进神经网络的学习方法
1. 代价函数选择
交叉熵（适用于s型神经元为主的网络解决学习缓慢问题）</br>
柔性最大值神经元层（具有对数似然代价的的学习缓慢问题）</br>
2. 网络调整
弃权（dropout）</br>
3. 各种情况
对于隐藏层权重为归一化高斯分布初始化（依然会产生学习缓慢问题）：使用均值为0标准差为1/根号（n）的高斯随机分布初始化权重。</br>
hold out：将验证集看成一种特殊的训练数据集，寻找更好的超参数，这种方法称为hold out</br>