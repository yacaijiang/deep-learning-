# 统计学习 
## 实现步骤：</br>
得到一个有限训练数据集合</br>
确定包含所有可能的模型的假设空间，学习模型集合</br>
确定模型选择的准则，即学习策略</br>
通过学习方法选择最优模型</br>
利用学习的最优模型对新数据进行预测或者分析</br>
## 监督学习
### 概念
学习一个模型，使模型能够对任意给定的输入，对其输出做出一个好的预测（输入输出指系统输入输出，非学习的输入输出）。</br>
输入空间、输出空间：将输入与输出所有可能的集合。可以是有限元素的集合，也可以是整个欧氏空间（欧氏空间是一个特别的度量空间，在包含了欧氏几何和非欧几何的流形的定义上发挥了作用。）。</br>
每个输入输出是一个实例，通常由特征向量表示，所有特征向量存在的空间称为特征空间。特征空间的每一维对应一个特征。
### 联合概率分布
### 假设空间
监督学习目的是学习一个由输入到输出的映射，这一映射由模型来表示，学习的目的在于找到最好的模型，模型属于由输入空间到输出空间的映射的集合。这个集合就是假设空间，假设空间确定意味着学习范围的确定。
### 问题形式化
监督学习分为：学习、预测
## 统计学习三要素
 ### 模型
 模型就是监督学习过程中，所要学习的条件概率分布或者决策函数，模型的假设空间包含所有可能的条件概率分布或者决策函数。
 ### 策略
 有了模型的假设空间，需要考虑按照什么样的准则学习或者选择最优模型，统计学习目标是从假设空间中选取最优模型。</br>
 损失函数：损失函数度量模型一次预测的好坏；</br>
 风险函数：度量平均意义下模型预测的好坏；</br>
 #### 损失函数
 用损失函数（loss）或者代价函数（cost）度量预测错误的程度。损失函数是f（X）和Y的非负实值函数</br>
 常用损失函数：0-1损失函数、平方损失函数、绝对损失函数、对数损失函数（对数似然损失函数）</br>
 损失函数的期望Rexp是f（X）关于联合分布P（X|Y）的平均意义下的损失称为风险函数（risk）或者期望损失（expected loss）</br>
 模型f（X）关于训练数据集的平均损失称为经验风险或者经验损失 记作Remp;
 ##### 经验风险最小化和结构风险最小化
 经验风险最小化：在假设空间、损失函数以及训练数据集确定的情况下，经验风险函数式确定，经验风险最小化（ERM）策略认为经验风险最小的模型是最优的模型。样本容量足够大的情况下，有很好的效果</br>
 结构分析最小化(SRM)：为了防止过拟合所提出的策略，结构风险最小化等价于正则化。结构风险在经验风险上加上表示模型复杂度的正则化项或罚项。结构风险最小化策略认为结构风险最小的模型是最优模型。
 ### 算法
 学习模型的具体计算方法，统计学习基于训练数据集，根据学习策略，从假设空间中选择最优模型，最后需要考虑如何求解最优模型。</br>
 ## 模型评估与模型选择
 基于损失函数的模型训练误差和模型的测试误差是学习方法评估的标准。</br>
 通常将学习方法对未知数据的预测能力称为泛化能力。</br>
 过拟合：学习时选择的模型包含参数过多，使得该模型对已知数据预测很好，对未知数据预测的很差。</br>
 ***常用模型选择方法：***</br>
 ***正则化***</br>
 结构风险最小化策略的实现，在经验风险上加一个正则化项或者罚项。正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大。</br>
 范数(norm)是数学中的一种基本概念。在泛函分析中，它定义在赋范线性空间中，并满足一定的条件，即①非负性；②齐次性；③三角不等式。它常常被用来度量某个向量空间（或矩阵）中的每个向量的长度或大小。</br>
 ***交叉验证***</br>
 给定样本数据充足，进行模型选择的一种简单方法是随机将数据集划分为三部分，分别为训练集、验证集、测试集。训练集用于训练模型，验证集用于模型的选择，测试集用于最终学习方法的评估。</br>
1. 简单交叉验证：首先随机将以给数据分为两部分，一部分作为训练集，另一部分作为测试集；然后用训练集在各种条件下训练模型，得到不同的模型，在测试集上评价各个模型的测试误差，选出测试误差最小的模型。
2. s折交叉验证：首先随机将以给数据切分成s个互不相交的大小相同的子集；然后利用s-1个子集的数据训练模型，利用余下的子集测试模型；将这一过程对可能的s种选择重复进行；最后选出s次评测中平均测试误差最小的模型；
3. 留一交叉验证：s折特殊情况，S=N，N为数据集的容量；
### 泛化能力
学习方法学习到的模型对未知数据的预测能力</br>
泛化误差：对学习到的模型，用该模型对未知数据预测的误差即为泛化误差。</br>
泛化误差上界：训练误差小的模型其泛化误差也会小</br>
### 生成模型、判别模型
生成方法由数据学习联合概率分布，求出条件概率分布作为预测模型，即生成模型,常见的朴素贝叶斯、隐马尔可夫模型</br>
判别方法由数据学习条件概率分布或决策函数作为预测模型，即判别模型，常见的有k近邻法、感知机、决策树、逻辑斯蒂回归模型、大熵模型、支持向量机、提升方法、条件随机场</br>
生成方法：可以还原出联合概率分布，学习收敛速度快，样本容量增加时学到的模型可以更快地收敛于真实模型；</br>
判别方法：学习准确率更高，可以对数据进行各种程度的抽象，定义并使用特征，简化学习问题
### 分类模型
 二分类常见评价指标：精确率和召回率</br>
通常预测类为正类，其他类为负类；</br>
TP:正类预测为正类；</br>
FN:正类预测为负类；</br>
FP:负类预测为正类；</br>
TN:负类预测为负类；</br>
精确率定义：P=TP/(TP+FP);</br>
召回率定义：R=TP/(TP+FN);</br>
F1:精确率和召回率的调和均值：2/F1=1/P + 1/R
F1=2TP/(2TP+FP+FN)
### 标注问题
标注是一个监督学习问题，是更复杂结构预测问题的简单形式</br>
### 回归问题
预测输入变量和输出变量之间的关系，当输入变量值发生变化时，输出变量的值随之发生变化，回归问题的学习等价于函数拟合，选择一条函数曲线使其很好的拟合已知数据且很好的预测未知数据。